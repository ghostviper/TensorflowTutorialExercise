{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "from mnist import MNIST\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST(data_dir=\"data/MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义基本的全局参数\n",
    "\n",
    "# 图像在每个维度上的像素值\n",
    "img_size = data.img_size\n",
    "\n",
    "# 图片展平后的像素值 img_size_flat\n",
    "img_size_flat = data.img_size_flat\n",
    "\n",
    "# 图像所包含的类别数\n",
    "num_classes = data.num_classes\n",
    "\n",
    "# 图像包含的通道数\n",
    "num_channels = data.num_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (55000, 784) test data shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 分割训练集和测试集和验证集\n",
    "x_train = data.x_train\n",
    "y_train = data.y_train\n",
    "\n",
    "x_test = data.x_test\n",
    "y_test = data.y_test\n",
    "\n",
    "print(\"train data shape:\", x_train.shape, \"test data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络所需的输入输出变量\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, img_size_flat], name=\"x\")\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=[None, num_classes], name=\"y_true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个卷积层\n",
    "# layer1：对28*28进行5*5的卷积 步长为1\n",
    "# 将layer1进行池化\n",
    "# layer2：对layer1输出的层进行5*5卷积 步长为2\n",
    "# 将layer2进行池化\n",
    "# 对池化层进行展平、进行dropout\n",
    "# 建立一个dense128 的隐层\n",
    "# 建立一个分类层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "filter_size1 = 5\n",
    "\n",
    "output_channels1 = 16\n",
    "# conv1\n",
    "# 定义卷积层\n",
    "# 定义卷积测weight参数 [filter_height, filter_width, input_channel, output_channel]\n",
    "weight = tf.Variable(tf.truncated_normal(shape=[filter_size1, filter_size1, num_channels, output_channels1], stddev=0.05))\n",
    "# 定义卷积层的bias参数\n",
    "bias = tf.Variable(tf.constant(0.05, shape=[output_channels1]))\n",
    "conv = tf.nn.conv2d(\n",
    "    input=x_image,\n",
    "    filter=weight,\n",
    "    strides=[1, 1, 1, 1],\n",
    "    padding=\"SAME\",\n",
    "    name=\"layer1\"\n",
    ")\n",
    "# 建模\n",
    "layer1 = tf.nn.relu(conv + bias)\n",
    "# 对第一层进行max_pooling\n",
    "max_pool1 = tf.nn.max_pool(layer1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.max_pool??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2\n",
    "filter_size2 = 5\n",
    "\n",
    "output_channels2 = 36\n",
    "\n",
    "weight2 = tf.Variable(tf.truncated_normal(shape=[filter_size2, filter_size2, output_channels1, output_channels2], stddev=0.05))\n",
    "# 定义卷积层的bias参数\n",
    "bias = tf.Variable(tf.constant(0.05, shape=[output_channels2]))\n",
    "\n",
    "conv2 = tf.nn.conv2d(\n",
    "    input=max_pool1,\n",
    "    filter=weight2,\n",
    "    strides=[1, 1, 1, 1],\n",
    "    padding='SAME'\n",
    ")\n",
    "\n",
    "layer2 = tf.nn.relu(conv2 + bias)\n",
    "\n",
    "max_pool2 = tf.nn.max_pool(layer2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(7), Dimension(7), Dimension(36)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(16)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对layer.get_shape()函数掌握不清楚这里需要借助该函数进行推到\n",
    "# layer.get_shape().num_features() 可以计算该层的参数个数\n",
    "conv_out_shape = max_pool2.get_shape()\n",
    "num_features = conv_out_shape[1:4].num_elements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将最后的卷积输出展平 然后进行池化\n",
    "flatten = tf.reshape(max_pool2, shape=[-1, num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer1 = tf.nn.dropout(flatten, keep_prob=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 1764) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 后接一个dense 128 的全连接层\n",
    "units_num = 128\n",
    "weight_dense1 = tf.Variable(tf.random_normal(shape=[num_features, units_num]))\n",
    "bias_dense1 = tf.constant(0.05, shape=[units_num])\n",
    "dense1 = tf.nn.relu(tf.matmul(output_layer1, weight_dense1) + bias_dense1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 后接类别数为num_classes的分类器\n",
    "weight_dense2 = tf.Variable(tf.random_normal(shape=[units_num, num_classes], stddev=0.05))\n",
    "bias_dense2 = tf.constant(0.05, shape=[num_classes])\n",
    "logits = tf.matmul(dense1, weight_dense2) + bias_dense2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(10)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输出的logits进行 softmax变换得出预测结果\n",
    "# 对预测结果和真实值进行对比衡量两个概率分布之间的差距 即求出cross_entropy\n",
    "# tf 提供了一个可以直接进行softmax激活并求出entropy\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器 对loss进行优化 \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=2e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义打印准确率的函数\n",
    "prediction = tf.nn.softmax(logits)\n",
    "# 对打印正确率的做法不清晰（numpy知识比较匮乏）\n",
    "# tf.argmax 返回的是指定维度最大元素的索引\n",
    "pred_cls = tf.argmax(prediction, axis=1)\n",
    "\n",
    "correct_prediction = tf.equal(pred_cls, tf.argmax(y_true, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建计算流图\n",
    "batch_size = 32\n",
    "num_iteration = 200\n",
    "total_iteration = 0\n",
    "session = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iteration = 0\n",
    "def optimize(num_iteration=200):\n",
    "    global total_iteration\n",
    "    for i in range(total_iteration, total_iteration + num_iteration):\n",
    "        x_batch, y_batch, y_cls_batch = data.random_batch(batch_size)\n",
    "        feed_train_data = {x:x_batch, y_true: y_batch}\n",
    "        session.run(optimizer, feed_dict=feed_train_data)\n",
    "        if i % 100 == 0:\n",
    "            acc = session.run(accuracy, feed_dict=feed_train_data)\n",
    "            print(\"total_iteration:\", total_iteration, \"acc:\", acc)\n",
    "    total_iteration += num_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_iteration: 0 acc: 0.125\n",
      "total_iteration: 0 acc: 0.40625\n",
      "total_iteration: 0 acc: 0.71875\n",
      "total_iteration: 0 acc: 0.6875\n",
      "total_iteration: 0 acc: 0.6875\n",
      "total_iteration: 0 acc: 0.875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.8125\n",
      "total_iteration: 0 acc: 0.84375\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.90625\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 0.9375\n",
      "total_iteration: 0 acc: 1.0\n",
      "total_iteration: 0 acc: 0.96875\n",
      "total_iteration: 0 acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "optimize(7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总结：\n",
    "#1. numpy函数和基本的操作需要加强\n",
    "#2. tf 变量初始化需要加强\n",
    "# 3.卷积层和池化层初始化参数理解"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
