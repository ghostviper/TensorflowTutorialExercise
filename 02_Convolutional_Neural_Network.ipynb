{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义神经网络所需要的基本参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一层卷积层的卷积核大小\n",
    "filter_size1 = 5\n",
    "# 第一层卷积核的个数\n",
    "num_filters1 = 16\n",
    "# 第二层卷积核的大小\n",
    "filter_size2 = 5\n",
    "# 第二层卷积核的大小\n",
    "num_filter2 = 36\n",
    "# 全连接层的大小\n",
    "fc_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 载入MNIST 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "data = MNIST(data_dir=\"data/MNIST/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的大小： 55000\n",
      "验证集的大小: 5000\n",
      "测试集的大小: 10000\n"
     ]
    }
   ],
   "source": [
    "# 查看数据集的大小\n",
    "print(\"训练集的大小：\", data.num_train)\n",
    "print(\"验证集的大小:\", data.num_val)\n",
    "print(\"测试集的大小:\", data.num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制数据维度信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图片展开的大小\n",
    "img_size_flat = data.img_size_flat\n",
    "\n",
    "#图片原始尺寸\n",
    "img_shape = data.img_shape\n",
    "\n",
    "# 类别数\n",
    "num_classes = data.num_classes\n",
    "\n",
    "#每个维度上图片的像素个数\n",
    "img_size = data.img_size\n",
    "\n",
    "# 图片的通道数\n",
    "num_channels = data.num_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow图简单说明\n",
    "- 占位符变量(placeholder)用来改变图的输入\n",
    "- 模型变量(Model)将会被优化，使得模型的表现更好\n",
    "- 模型本质上就是一些数学函数，它根据placeholder和模型的输入变量来计算一些输出\n",
    "- 一个cost度量用来指导变量的优化\n",
    "- 一个优化策略会更新模型的变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建新变量的帮助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.truncated_normal??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_biases(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.constant??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积层的帮助函数\n",
    "\n",
    "假设输入的四维张量，各个维度如下\n",
    "\n",
    "1.图像数量 \n",
    "\n",
    "2.每张图像的Y轴 \n",
    "\n",
    "3.每张图像的X轴 \n",
    "\n",
    "4.每张图像的通道数 \n",
    "\n",
    "\n",
    "输入图片的张量的时候可能是彩色的通道即红绿蓝，当输入是前一层卷积层生成的输出的时候，它可能是滤波通道\n",
    "\n",
    "输出是另外一个四通道的张量，如下\n",
    "1.图像数量，与输入相同 \n",
    "\n",
    "2.每张图的Y轴，如果用了2x2的池化，则输入是图像宽高的一半 \n",
    "\n",
    "3.每张图像的X轴 \n",
    "\n",
    "4.卷积滤波生成的通道数 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_conv_layer(input, num_input_channels, filter_size, num_filters, use_pooling=True):\n",
    "    # 定义输入张量的形状\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    # 初始化当前层的weights\n",
    "    weights = new_weights(shape=shape)\n",
    "    # 初始化biases\n",
    "    biases = new_biases(length=num_filters)\n",
    "    # 建立一个卷积\n",
    "    layer = tf.nn.conv2d(\n",
    "        input=input,\n",
    "        filter=weights,\n",
    "        strides=[1, 1, 1, 1],\n",
    "        padding='SAME'\n",
    "    )\n",
    "    layer += biases\n",
    "    if use_pooling is True:\n",
    "        # 进行池化层操作\n",
    "        # 初始化参数为： 输入层、卷积核大小2x2，步长高宽2，2，填充0\n",
    "        layer = tf.nn.max_pool(\n",
    "            value=layer,\n",
    "            ksize=[1, 2, 2, 1],\n",
    "            strides=[1, 2, 2, 1],\n",
    "            padding='SAME'\n",
    "        )\n",
    "    # 对卷积的输出或池化层进行激活\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reshape??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转换一个层的帮助函数\n",
    "\n",
    "卷积层生成四维的张量，我们会在卷积层后添加一个全连接层，将这个四维张量转换为2维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # 获取layer的shape\n",
    "    layer_shape = layer.get_shape()\n",
    "    # layer_shape = [num_images, img_height, img_width, num_channels]\n",
    "    # 根据维度计算参数个数\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    # 展平张量 reshape 其中一个维度设置为-1 表示自动计算剩余的维度\n",
    "    layer_flat = tf.reshape(layer, shape=[-1, num_features])\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建一个全连接层的帮助函数\n",
    "输入大小是\\[num_images, num_inputs\\],输出大小是\\[num_images, num_outputs\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fc_layer(input, num_inputs, num_outputs, use_relu=True):\n",
    "    weights = new_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = new_biases(length=num_outputs)\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu is True:\n",
    "        layer = tf.nn.relu(layer)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 声明占位符变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist输入图像的大小为多张 形状为img_size_flat大小的向量\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, img_size_flat], name='x')\n",
    "# 卷积层接受的是[image_num, image_height, image_width, num_channels]的四维张量，需要用reshape进行变换\n",
    "x_image = tf.reshape(x, shape=[-1, img_size, img_size, num_channels])\n",
    "# 定义真实类别\n",
    "y_true = tf.placeholder(dtype=tf.float32, shape=[None, num_classes])\n",
    "# sparse 真实类别\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义第一个卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1, weights1 = new_conv_layer(\n",
    "    input=x_image, \n",
    "    num_input_channels=num_channels, \n",
    "    filter_size=filter_size1, \n",
    "    num_filters=num_filters1, \n",
    "    use_pooling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 14, 14, 16) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义第二个卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2, weights2 = new_conv_layer(\n",
    "    input=layer1,\n",
    "    num_input_channels=num_filters1,\n",
    "    filter_size=filter_size2,\n",
    "    num_filters=num_filter2,\n",
    "    use_pooling=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_3:0' shape=(?, 7, 7, 36) dtype=float32>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将卷积层展平"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立全连接层1\n",
    "输出为128维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(\n",
    "    input=layer_flat, \n",
    "    num_inputs=num_features, \n",
    "    num_outputs=fc_size, \n",
    "    use_relu=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立全连接层2\n",
    "输出为num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(\n",
    "    input=layer_fc1,\n",
    "    num_inputs=fc_size,\n",
    "    num_outputs=num_classes,\n",
    "    use_relu=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_4:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_6:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立损失函数对logits进行损失计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总体的损失估计\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=layer_fc2, labels=y_true)\n",
    "# 利用平均损失估计进行度量\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立优化方法进行优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 性能度量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(tf.nn.softmax(layer_fc2))\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1.复习建模的整个流程：初始化变量-》建模-》建立损失函数-》建立优化器-》建立性能评估\n",
    "\n",
    "2.复习卷积层、池化层、激活函数的参数用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
